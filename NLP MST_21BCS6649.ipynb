{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a824be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a97cad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['The', 'quick', 'brown', 'foxes', 'are', 'jumping', 'over', 'the', 'lazy', 'dogs']\n",
      "Stemmed Tokens: ['the', 'quick', 'brown', 'fox', 'are', 'jump', 'over', 'the', 'lazi', 'dog']\n",
      "Lemmatized Tokens: ['The', 'quick', 'brown', 'fox', 'are', 'jumping', 'over', 'the', 'lazy', 'dog']\n",
      "Filtered Tokens (without stop words): ['quick', 'brown', 'foxes', 'jumping', 'lazy', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "# Sample text for demonstration\n",
    "text = \"The quick brown foxes are jumping over the lazy dogs\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "print(\"Lemmatized Tokens:\", lemmatized_tokens)\n",
    "\n",
    "# Stop words removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "print(\"Filtered Tokens (without stop words):\", filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b71e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Rohit Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['The', 'quick', 'brown', 'foxes', 'are', 'jumping', 'over', 'the', 'lazy', 'dogs', '.', 'John', 'works', 'at', 'Google', 'and', 'lives', 'in', 'New', 'York', '.']\n",
      "Stemmed Tokens: ['the', 'quick', 'brown', 'fox', 'are', 'jump', 'over', 'the', 'lazi', 'dog', '.', 'john', 'work', 'at', 'googl', 'and', 'live', 'in', 'new', 'york', '.']\n",
      "Lemmatized Tokens: ['The', 'quick', 'brown', 'fox', 'are', 'jumping', 'over', 'the', 'lazy', 'dog', '.', 'John', 'work', 'at', 'Google', 'and', 'life', 'in', 'New', 'York', '.']\n",
      "Filtered Tokens (without stop words): ['quick', 'brown', 'foxes', 'jumping', 'lazy', 'dogs', '.', 'John', 'works', 'Google', 'lives', 'New', 'York', '.']\n",
      "Named Entities:\n",
      "PERSON John\n",
      "ORGANIZATION Google\n",
      "GPE New York\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# Sample text for demonstration\n",
    "text = \"The quick brown foxes are jumping over the lazy dogs. John works at Google and lives in New York.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "print(\"Lemmatized Tokens:\", lemmatized_tokens)\n",
    "\n",
    "# Stop words removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "print(\"Filtered Tokens (without stop words):\", filtered_tokens)\n",
    "\n",
    "# Named Entity Recognition (NER)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "ner_tags = ne_chunk(pos_tags)\n",
    "print(\"Named Entities:\")\n",
    "for chunk in ner_tags:\n",
    "    if hasattr(chunk, 'label'):\n",
    "        print(chunk.label(), ' '.join(c[0] for c in chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb073869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "261e66e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Once', 'upon', 'a', 'time', ',', 'in', 'the', 'enchanting', 'kingdom', 'of', 'Arindale', ',', 'nestled', 'amidst', 'rolling', 'hills', 'and', 'lush', 'forests', ',', 'there', 'lived', 'a', 'young', 'sorcerer', 'named', 'Aiden', '.', 'Aiden', 'was', 'known', 'throughout', 'the', 'land', 'for', 'his', 'exceptional', 'magical', 'abilities', ',', 'which', 'he', 'inherited', 'from', 'his', 'ancestors', 'who', 'were', 'renowned', 'wizards', '.', 'One', 'crisp', 'autumn', 'morning', ',', 'as', 'the', 'leaves', 'turned', 'golden', 'and', 'the', 'air', 'carried', 'a', 'hint', 'of', 'magic', ',', 'Aiden', 'received', 'a', 'mysterious', 'letter', 'sealed', 'with', 'shimmering', 'gold', 'wax', '.', 'The', 'letter', 'bore', 'the', 'royal', 'crest', 'of', 'King', 'Aric', ',', 'summoning', 'Aiden', 'to', 'the', 'majestic', 'Castle', 'Evergreen', 'for', 'an', 'urgent', 'audience', 'with', 'the', 'king', '.', 'Intrigued', 'and', 'filled', 'with', 'a', 'sense', 'of', 'foreboding', ',', 'Aiden', 'embarked', 'on', 'a', 'journey', 'to', 'Castle', 'Evergreen', ',', 'accompanied', 'by', 'his', 'faithful', 'companion', ',', 'a', 'mischievous', 'talking', 'raven', 'named', 'Merlin', '.', 'Along', 'the', 'way', ',', 'they', 'encountered', 'enchanted', 'forests', ',', 'sparkling', 'streams', ',', 'and', 'mystical', 'creatures', 'that', 'roamed', 'the', 'countryside', '.', 'Upon', 'reaching', 'Castle', 'Evergreen', ',', 'Aiden', 'was', 'ushered', 'into', 'the', 'grand', 'throne', 'room', 'where', 'King', 'Aric', 'awaited', 'him', 'with', 'a', 'grave', 'expression', '.', 'The', 'king', 'revealed', 'that', 'the', 'kingdom', 'was', 'under', 'a', 'dark', 'curse', 'cast', 'by', 'an', 'evil', 'sorcerer', ',', 'threatening', 'to', 'plunge', 'Arindale', 'into', 'eternal', 'darkness', '.', 'Determined', 'to', 'save', 'his', 'homeland', ',', 'Aiden', 'embarked', 'on', 'a', 'perilous', 'quest', 'to', 'seek', 'the', 'legendary', 'Sword', 'of', 'Light', ',', 'the', 'only', 'weapon', 'capable', 'of', 'breaking', 'the', 'curse', '.', 'Guided', 'by', 'ancient', 'prophecies', 'and', 'aided', 'by', 'magical', 'allies', ',', 'Aiden', 'journeyed', 'to', 'the', 'heart', 'of', 'the', 'Forbidden', 'Forest', ',', 'where', 'the', 'sword', 'lay', 'hidden', '.']\n",
      "POS Tags: [('Once', 'RB'), ('upon', 'IN'), ('a', 'DT'), ('time', 'NN'), (',', ','), ('in', 'IN'), ('the', 'DT'), ('enchanting', 'VBG'), ('kingdom', 'NN'), ('of', 'IN'), ('Arindale', 'NNP'), (',', ','), ('nestled', 'VBD'), ('amidst', 'RP'), ('rolling', 'VBG'), ('hills', 'NNS'), ('and', 'CC'), ('lush', 'JJ'), ('forests', 'NNS'), (',', ','), ('there', 'EX'), ('lived', 'VBD'), ('a', 'DT'), ('young', 'JJ'), ('sorcerer', 'NN'), ('named', 'VBN'), ('Aiden', 'NNP'), ('.', '.'), ('Aiden', 'NNP'), ('was', 'VBD'), ('known', 'VBN'), ('throughout', 'IN'), ('the', 'DT'), ('land', 'NN'), ('for', 'IN'), ('his', 'PRP$'), ('exceptional', 'JJ'), ('magical', 'JJ'), ('abilities', 'NNS'), (',', ','), ('which', 'WDT'), ('he', 'PRP'), ('inherited', 'VBD'), ('from', 'IN'), ('his', 'PRP$'), ('ancestors', 'NNS'), ('who', 'WP'), ('were', 'VBD'), ('renowned', 'VBN'), ('wizards', 'NNS'), ('.', '.'), ('One', 'CD'), ('crisp', 'NN'), ('autumn', 'NN'), ('morning', 'NN'), (',', ','), ('as', 'IN'), ('the', 'DT'), ('leaves', 'NNS'), ('turned', 'VBD'), ('golden', 'JJ'), ('and', 'CC'), ('the', 'DT'), ('air', 'NN'), ('carried', 'VBD'), ('a', 'DT'), ('hint', 'NN'), ('of', 'IN'), ('magic', 'NN'), (',', ','), ('Aiden', 'NNP'), ('received', 'VBD'), ('a', 'DT'), ('mysterious', 'JJ'), ('letter', 'NN'), ('sealed', 'VBN'), ('with', 'IN'), ('shimmering', 'VBG'), ('gold', 'NN'), ('wax', 'NN'), ('.', '.'), ('The', 'DT'), ('letter', 'NN'), ('bore', 'VBD'), ('the', 'DT'), ('royal', 'JJ'), ('crest', 'NN'), ('of', 'IN'), ('King', 'NNP'), ('Aric', 'NNP'), (',', ','), ('summoning', 'VBG'), ('Aiden', 'NNP'), ('to', 'TO'), ('the', 'DT'), ('majestic', 'JJ'), ('Castle', 'NNP'), ('Evergreen', 'NNP'), ('for', 'IN'), ('an', 'DT'), ('urgent', 'JJ'), ('audience', 'NN'), ('with', 'IN'), ('the', 'DT'), ('king', 'NN'), ('.', '.'), ('Intrigued', 'VBN'), ('and', 'CC'), ('filled', 'VBN'), ('with', 'IN'), ('a', 'DT'), ('sense', 'NN'), ('of', 'IN'), ('foreboding', 'NN'), (',', ','), ('Aiden', 'NNP'), ('embarked', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('journey', 'NN'), ('to', 'TO'), ('Castle', 'NNP'), ('Evergreen', 'NNP'), (',', ','), ('accompanied', 'VBN'), ('by', 'IN'), ('his', 'PRP$'), ('faithful', 'JJ'), ('companion', 'NN'), (',', ','), ('a', 'DT'), ('mischievous', 'JJ'), ('talking', 'VBG'), ('raven', 'NN'), ('named', 'VBN'), ('Merlin', 'NNP'), ('.', '.'), ('Along', 'IN'), ('the', 'DT'), ('way', 'NN'), (',', ','), ('they', 'PRP'), ('encountered', 'VBD'), ('enchanted', 'JJ'), ('forests', 'NNS'), (',', ','), ('sparkling', 'VBG'), ('streams', 'NNS'), (',', ','), ('and', 'CC'), ('mystical', 'JJ'), ('creatures', 'NNS'), ('that', 'WDT'), ('roamed', 'VBD'), ('the', 'DT'), ('countryside', 'NN'), ('.', '.'), ('Upon', 'IN'), ('reaching', 'VBG'), ('Castle', 'NNP'), ('Evergreen', 'NNP'), (',', ','), ('Aiden', 'NNP'), ('was', 'VBD'), ('ushered', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('grand', 'JJ'), ('throne', 'NN'), ('room', 'NN'), ('where', 'WRB'), ('King', 'NNP'), ('Aric', 'NNP'), ('awaited', 'VBD'), ('him', 'PRP'), ('with', 'IN'), ('a', 'DT'), ('grave', 'JJ'), ('expression', 'NN'), ('.', '.'), ('The', 'DT'), ('king', 'NN'), ('revealed', 'VBD'), ('that', 'IN'), ('the', 'DT'), ('kingdom', 'NN'), ('was', 'VBD'), ('under', 'IN'), ('a', 'DT'), ('dark', 'JJ'), ('curse', 'NN'), ('cast', 'NN'), ('by', 'IN'), ('an', 'DT'), ('evil', 'JJ'), ('sorcerer', 'NN'), (',', ','), ('threatening', 'VBG'), ('to', 'TO'), ('plunge', 'VB'), ('Arindale', 'NNP'), ('into', 'IN'), ('eternal', 'JJ'), ('darkness', 'NN'), ('.', '.'), ('Determined', 'VBN'), ('to', 'TO'), ('save', 'VB'), ('his', 'PRP$'), ('homeland', 'NN'), (',', ','), ('Aiden', 'NNP'), ('embarked', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('perilous', 'JJ'), ('quest', 'NN'), ('to', 'TO'), ('seek', 'VB'), ('the', 'DT'), ('legendary', 'JJ'), ('Sword', 'NNP'), ('of', 'IN'), ('Light', 'NNP'), (',', ','), ('the', 'DT'), ('only', 'JJ'), ('weapon', 'NN'), ('capable', 'JJ'), ('of', 'IN'), ('breaking', 'VBG'), ('the', 'DT'), ('curse', 'NN'), ('.', '.'), ('Guided', 'VBN'), ('by', 'IN'), ('ancient', 'JJ'), ('prophecies', 'NNS'), ('and', 'CC'), ('aided', 'VBN'), ('by', 'IN'), ('magical', 'JJ'), ('allies', 'NNS'), (',', ','), ('Aiden', 'NNP'), ('journeyed', 'NN'), ('to', 'TO'), ('the', 'DT'), ('heart', 'NN'), ('of', 'IN'), ('the', 'DT'), ('Forbidden', 'NNP'), ('Forest', 'NNP'), (',', ','), ('where', 'WRB'), ('the', 'DT'), ('sword', 'NN'), ('lay', 'VBD'), ('hidden', 'NN'), ('.', '.')]\n",
      "Stemmed Tokens: ['onc', 'upon', 'a', 'time', ',', 'in', 'the', 'enchant', 'kingdom', 'of', 'arindal', ',', 'nestl', 'amidst', 'roll', 'hill', 'and', 'lush', 'forest', ',', 'there', 'live', 'a', 'young', 'sorcer', 'name', 'aiden', '.', 'aiden', 'wa', 'known', 'throughout', 'the', 'land', 'for', 'hi', 'except', 'magic', 'abil', ',', 'which', 'he', 'inherit', 'from', 'hi', 'ancestor', 'who', 'were', 'renown', 'wizard', '.', 'one', 'crisp', 'autumn', 'morn', ',', 'as', 'the', 'leav', 'turn', 'golden', 'and', 'the', 'air', 'carri', 'a', 'hint', 'of', 'magic', ',', 'aiden', 'receiv', 'a', 'mysteri', 'letter', 'seal', 'with', 'shimmer', 'gold', 'wax', '.', 'the', 'letter', 'bore', 'the', 'royal', 'crest', 'of', 'king', 'aric', ',', 'summon', 'aiden', 'to', 'the', 'majest', 'castl', 'evergreen', 'for', 'an', 'urgent', 'audienc', 'with', 'the', 'king', '.', 'intrigu', 'and', 'fill', 'with', 'a', 'sens', 'of', 'forebod', ',', 'aiden', 'embark', 'on', 'a', 'journey', 'to', 'castl', 'evergreen', ',', 'accompani', 'by', 'hi', 'faith', 'companion', ',', 'a', 'mischiev', 'talk', 'raven', 'name', 'merlin', '.', 'along', 'the', 'way', ',', 'they', 'encount', 'enchant', 'forest', ',', 'sparkl', 'stream', ',', 'and', 'mystic', 'creatur', 'that', 'roam', 'the', 'countrysid', '.', 'upon', 'reach', 'castl', 'evergreen', ',', 'aiden', 'wa', 'usher', 'into', 'the', 'grand', 'throne', 'room', 'where', 'king', 'aric', 'await', 'him', 'with', 'a', 'grave', 'express', '.', 'the', 'king', 'reveal', 'that', 'the', 'kingdom', 'wa', 'under', 'a', 'dark', 'curs', 'cast', 'by', 'an', 'evil', 'sorcer', ',', 'threaten', 'to', 'plung', 'arindal', 'into', 'etern', 'dark', '.', 'determin', 'to', 'save', 'hi', 'homeland', ',', 'aiden', 'embark', 'on', 'a', 'peril', 'quest', 'to', 'seek', 'the', 'legendari', 'sword', 'of', 'light', ',', 'the', 'onli', 'weapon', 'capabl', 'of', 'break', 'the', 'curs', '.', 'guid', 'by', 'ancient', 'propheci', 'and', 'aid', 'by', 'magic', 'alli', ',', 'aiden', 'journey', 'to', 'the', 'heart', 'of', 'the', 'forbidden', 'forest', ',', 'where', 'the', 'sword', 'lay', 'hidden', '.']\n",
      "Lemmatized Tokens: ['Once', 'upon', 'a', 'time', ',', 'in', 'the', 'enchanting', 'kingdom', 'of', 'Arindale', ',', 'nestled', 'amidst', 'rolling', 'hill', 'and', 'lush', 'forest', ',', 'there', 'lived', 'a', 'young', 'sorcerer', 'named', 'Aiden', '.', 'Aiden', 'wa', 'known', 'throughout', 'the', 'land', 'for', 'his', 'exceptional', 'magical', 'ability', ',', 'which', 'he', 'inherited', 'from', 'his', 'ancestor', 'who', 'were', 'renowned', 'wizard', '.', 'One', 'crisp', 'autumn', 'morning', ',', 'a', 'the', 'leaf', 'turned', 'golden', 'and', 'the', 'air', 'carried', 'a', 'hint', 'of', 'magic', ',', 'Aiden', 'received', 'a', 'mysterious', 'letter', 'sealed', 'with', 'shimmering', 'gold', 'wax', '.', 'The', 'letter', 'bore', 'the', 'royal', 'crest', 'of', 'King', 'Aric', ',', 'summoning', 'Aiden', 'to', 'the', 'majestic', 'Castle', 'Evergreen', 'for', 'an', 'urgent', 'audience', 'with', 'the', 'king', '.', 'Intrigued', 'and', 'filled', 'with', 'a', 'sense', 'of', 'foreboding', ',', 'Aiden', 'embarked', 'on', 'a', 'journey', 'to', 'Castle', 'Evergreen', ',', 'accompanied', 'by', 'his', 'faithful', 'companion', ',', 'a', 'mischievous', 'talking', 'raven', 'named', 'Merlin', '.', 'Along', 'the', 'way', ',', 'they', 'encountered', 'enchanted', 'forest', ',', 'sparkling', 'stream', ',', 'and', 'mystical', 'creature', 'that', 'roamed', 'the', 'countryside', '.', 'Upon', 'reaching', 'Castle', 'Evergreen', ',', 'Aiden', 'wa', 'ushered', 'into', 'the', 'grand', 'throne', 'room', 'where', 'King', 'Aric', 'awaited', 'him', 'with', 'a', 'grave', 'expression', '.', 'The', 'king', 'revealed', 'that', 'the', 'kingdom', 'wa', 'under', 'a', 'dark', 'curse', 'cast', 'by', 'an', 'evil', 'sorcerer', ',', 'threatening', 'to', 'plunge', 'Arindale', 'into', 'eternal', 'darkness', '.', 'Determined', 'to', 'save', 'his', 'homeland', ',', 'Aiden', 'embarked', 'on', 'a', 'perilous', 'quest', 'to', 'seek', 'the', 'legendary', 'Sword', 'of', 'Light', ',', 'the', 'only', 'weapon', 'capable', 'of', 'breaking', 'the', 'curse', '.', 'Guided', 'by', 'ancient', 'prophecy', 'and', 'aided', 'by', 'magical', 'ally', ',', 'Aiden', 'journeyed', 'to', 'the', 'heart', 'of', 'the', 'Forbidden', 'Forest', ',', 'where', 'the', 'sword', 'lay', 'hidden', '.']\n",
      "Filtered Tokens (without stop words): ['upon', 'time', ',', 'enchanting', 'kingdom', 'Arindale', ',', 'nestled', 'amidst', 'rolling', 'hills', 'lush', 'forests', ',', 'lived', 'young', 'sorcerer', 'named', 'Aiden', '.', 'Aiden', 'known', 'throughout', 'land', 'exceptional', 'magical', 'abilities', ',', 'inherited', 'ancestors', 'renowned', 'wizards', '.', 'One', 'crisp', 'autumn', 'morning', ',', 'leaves', 'turned', 'golden', 'air', 'carried', 'hint', 'magic', ',', 'Aiden', 'received', 'mysterious', 'letter', 'sealed', 'shimmering', 'gold', 'wax', '.', 'letter', 'bore', 'royal', 'crest', 'King', 'Aric', ',', 'summoning', 'Aiden', 'majestic', 'Castle', 'Evergreen', 'urgent', 'audience', 'king', '.', 'Intrigued', 'filled', 'sense', 'foreboding', ',', 'Aiden', 'embarked', 'journey', 'Castle', 'Evergreen', ',', 'accompanied', 'faithful', 'companion', ',', 'mischievous', 'talking', 'raven', 'named', 'Merlin', '.', 'Along', 'way', ',', 'encountered', 'enchanted', 'forests', ',', 'sparkling', 'streams', ',', 'mystical', 'creatures', 'roamed', 'countryside', '.', 'Upon', 'reaching', 'Castle', 'Evergreen', ',', 'Aiden', 'ushered', 'grand', 'throne', 'room', 'King', 'Aric', 'awaited', 'grave', 'expression', '.', 'king', 'revealed', 'kingdom', 'dark', 'curse', 'cast', 'evil', 'sorcerer', ',', 'threatening', 'plunge', 'Arindale', 'eternal', 'darkness', '.', 'Determined', 'save', 'homeland', ',', 'Aiden', 'embarked', 'perilous', 'quest', 'seek', 'legendary', 'Sword', 'Light', ',', 'weapon', 'capable', 'breaking', 'curse', '.', 'Guided', 'ancient', 'prophecies', 'aided', 'magical', 'allies', ',', 'Aiden', 'journeyed', 'heart', 'Forbidden', 'Forest', ',', 'sword', 'lay', 'hidden', '.']\n",
      "Named Entities:\n",
      "GPE Arindale\n",
      "PERSON Aiden\n",
      "PERSON Aiden\n",
      "PERSON Aiden\n",
      "PERSON Aiden\n",
      "PERSON Castle Evergreen\n",
      "PERSON Aiden\n",
      "PERSON Castle Evergreen\n",
      "PERSON Merlin\n",
      "PERSON Castle Evergreen\n",
      "PERSON Aiden\n",
      "PERSON Aric\n",
      "PERSON Arindale\n",
      "PERSON Aiden\n",
      "GPE Light\n",
      "PERSON Aiden\n",
      "ORGANIZATION Forbidden Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Rohit Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Rohit\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# Sample text for demonstration\n",
    "text = \"\"\"Once upon a time, in the enchanting kingdom of Arindale, nestled amidst rolling hills and lush forests, there lived a young sorcerer named Aiden. Aiden was known throughout the land for his exceptional magical abilities, which he inherited from his ancestors who were renowned wizards.\n",
    "One crisp autumn morning, as the leaves turned golden and the air carried a hint of magic, Aiden received a mysterious letter sealed with shimmering gold wax. The letter bore the royal crest of King Aric, summoning Aiden to the majestic Castle Evergreen for an urgent audience with the king.\n",
    "Intrigued and filled with a sense of foreboding, Aiden embarked on a journey to Castle Evergreen, accompanied by his faithful companion, a mischievous talking raven named Merlin. Along the way, they encountered enchanted forests, sparkling streams, and mystical creatures that roamed the countryside.\n",
    "Upon reaching Castle Evergreen, Aiden was ushered into the grand throne room where King Aric awaited him with a grave expression. The king revealed that the kingdom was under a dark curse cast by an evil sorcerer, threatening to plunge Arindale into eternal darkness.\n",
    "Determined to save his homeland, Aiden embarked on a perilous quest to seek the legendary Sword of Light, the only weapon capable of breaking the curse. Guided by ancient prophecies and aided by magical allies, Aiden journeyed to the heart of the Forbidden Forest, where the sword lay hidden.\"\"\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# POS Tagging\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(\"POS Tags:\", pos_tags)\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "print(\"Lemmatized Tokens:\", lemmatized_tokens)\n",
    "\n",
    "# Stop words removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "print(\"Filtered Tokens (without stop words):\", filtered_tokens)\n",
    "\n",
    "# Named Entity Recognition (NER)\n",
    "ner_tags = ne_chunk(pos_tags)\n",
    "print(\"Named Entities:\")\n",
    "for chunk in ner_tags:\n",
    "    if hasattr(chunk, 'label'):\n",
    "        print(chunk.label(), ' '.join(c[0] for c in chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e50b44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entity Frequencies:\n",
      "Arindale: 2\n",
      "Aiden: 8\n",
      "Castle Evergreen: 3\n",
      "Merlin: 1\n",
      "Aric: 1\n",
      "Light: 1\n",
      "Forbidden Forest: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Named entity recognition output\n",
    "ner_output = [\n",
    "    ('GPE', 'Arindale'),\n",
    "    ('PERSON', 'Aiden'),\n",
    "    ('PERSON', 'Aiden'),\n",
    "    ('PERSON', 'Aiden'),\n",
    "    ('PERSON', 'Aiden'),\n",
    "    ('PERSON', 'Castle Evergreen'),\n",
    "    ('PERSON', 'Aiden'),\n",
    "    ('PERSON', 'Castle Evergreen'),\n",
    "    ('PERSON', 'Merlin'),\n",
    "    ('PERSON', 'Castle Evergreen'),\n",
    "    ('PERSON', 'Aiden'),\n",
    "    ('PERSON', 'Aric'),\n",
    "    ('PERSON', 'Arindale'),\n",
    "    ('PERSON', 'Aiden'),\n",
    "    ('GPE', 'Light'),\n",
    "    ('PERSON', 'Aiden'),\n",
    "    ('ORGANIZATION', 'Forbidden Forest')\n",
    "]\n",
    "\n",
    "# Count the frequency of named entities\n",
    "entity_counts = Counter([entity[1] for entity in ner_output if entity[0] in ['PERSON', 'GPE', 'ORGANIZATION']])\n",
    "\n",
    "# Print the entity counts\n",
    "print(\"Named Entity Frequencies:\")\n",
    "for entity, count in entity_counts.items():\n",
    "    print(f\"{entity}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6885721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
